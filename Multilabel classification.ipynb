{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm\n",
    "import pickle\n",
    "import flake8\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils.data import Vocabulary\n",
    "from utils.mtl.data import CreatorDataset\n",
    "from utils.mtl.model import Doc2Vec, BiTaskLSTMModel, MultiTaskLossWrapper\n",
    "from utils.mtl.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext pycodestyle_magic\n",
    "%flake8_on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data.pickle', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Инициализация словаря**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['actions'].values\n",
    "targets = df[['target1', 'target2']].values\n",
    "\n",
    "voc = Vocabulary(max_vocab_size=1000, min_freq=2)\n",
    "corpus_voc = voc.transform(corpus)\n",
    "corpus_voc = [doc for doc in corpus_voc if np.any(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Инициализация датасета и даталоадера**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.6\n",
    "test_size = 0.2\n",
    "\n",
    "idx_train = int(len(corpus_voc) * train_size)\n",
    "idx_test = int(len(corpus_voc) * train_size) + int(len(corpus_voc) * test_size)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "ds_train = CreatorDataset(corpus=corpus_voc[:idx_train],\n",
    "                          targets=targets[:idx_test], maxlen=20)\n",
    "ds_val = CreatorDataset(corpus=corpus_voc[idx_train:idx_test],\n",
    "                        targets=targets[idx_train:idx_test], maxlen=20)\n",
    "ds_test = CreatorDataset(corpus=corpus_voc[idx_test:],\n",
    "                         targets=targets[idx_test:], maxlen=20)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "dl_val = DataLoader(ds_val, batch_size=batch_size, shuffle=True)\n",
    "dl_test = DataLoader(ds_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Инициализация модели doc2vec, функции ошибки и оптимизатора**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_embeddings = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Doc2Vec(voc.vocab_size, dim_embeddings=dim_embeddings)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = MultiTaskLossWrapper()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучение модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 190.52it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 270.14it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 248.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0| train loss: 0.6457, test loss: 0.6056\n",
      "epoch: 1| train loss: 0.6096, test loss: 0.5733\n",
      "epoch: 2| train loss: 0.5854, test loss: 0.5530\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, criterion, device, learning_rate)\n",
    "losses = trainer.train(dl_train, dl_val, n_epochs=3, gap=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0 task: 0.9286\n",
      "score 1 task: 0.6400\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(dl_test)\n",
    "\n",
    "for i in range(2):\n",
    "    print('score {} task: {:.4f}'.format(i, roc_auc_score(ds_test.targets[:, i], preds[:, i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Инициализация и обучение модели LSTM на 2 задачи**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiTaskLSTMModel(voc.vocab_size, dim_embeddings=dim_embeddings)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = MultiTaskLossWrapper()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:12<00:00,  1.23it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0| train loss: 0.6859, test loss: 0.6271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:11<00:00,  1.33it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1| train loss: 0.5857, test loss: 0.5292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:10<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2| train loss: 0.4828, test loss: 0.4414\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, criterion, device, learning_rate)\n",
    "losses = trainer.train(dl_train, dl_val, n_epochs=3, gap=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0 task: 0.7619\n",
      "score 1 task: 0.6800\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(dl_test)\n",
    "\n",
    "for i in range(2):\n",
    "    print('score {} task: {:.4f}'.format(i, roc_auc_score(ds_test.targets[:, i], preds[:, i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Низкое и нестабильное качество моделей связано с очень малым объемом данных**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
